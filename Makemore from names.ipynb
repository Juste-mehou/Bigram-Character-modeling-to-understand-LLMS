{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401b9f5c-91f1-4adf-90d4-b93be47496e2",
   "metadata": {},
   "source": [
    "### Bigram character level language modeling\n",
    "\n",
    "This project was an exploration of how language models are trained at a really simple level. \n",
    "\n",
    "Large language models are trained to predict the next most likely token. This model is a basic precursor of the transformer architecture used to train LLMs. I used it to predict the next most likely letter given a previous letter to create name-like words following the tutorial by Andrej Karpathy on Youtube [here](https://www.youtube.com/watch?v=PaCmpygFfXo) . The dataset used is the large dataset of names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9e5a71b-2ffe-432b-9670-89f18c283cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_r = open(\"names.txt\").read() # Import names dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c44cdc4-6698-43d6-a630-b7fc7ea2d014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 'm',\n",
       " 'm',\n",
       " 'a',\n",
       " '.',\n",
       " 'o',\n",
       " 'l',\n",
       " 'i',\n",
       " 'v',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'v',\n",
       " 'a',\n",
       " '.',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'b',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 's',\n",
       " 'o',\n",
       " 'p',\n",
       " 'h',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'l',\n",
       " 'o',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " '.',\n",
       " 'm',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'h',\n",
       " 'a',\n",
       " 'r',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " '.',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'b',\n",
       " 'i',\n",
       " 'g',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " '.',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'l',\n",
       " 'y',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " '.',\n",
       " 'm',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'y',\n",
       " '.',\n",
       " 's',\n",
       " 'o',\n",
       " 'f',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'c',\n",
       " 'a',\n",
       " 'm',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 's',\n",
       " 'c',\n",
       " 'a',\n",
       " 'r',\n",
       " 'l',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " '.',\n",
       " 'v',\n",
       " 'i',\n",
       " 'c',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " '.',\n",
       " 'l',\n",
       " 'u',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'g',\n",
       " 'r',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " '.',\n",
       " 'c',\n",
       " 'h',\n",
       " 'l',\n",
       " 'o',\n",
       " 'e',\n",
       " '.',\n",
       " 'p',\n",
       " 'e',\n",
       " 'n',\n",
       " 'e',\n",
       " 'l',\n",
       " 'o',\n",
       " 'p',\n",
       " 'e',\n",
       " '.',\n",
       " 'l',\n",
       " 'a',\n",
       " 'y',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'r',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'z',\n",
       " 'o',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " '.',\n",
       " 'l',\n",
       " 'i',\n",
       " 'l',\n",
       " 'y',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " '.',\n",
       " 'h',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'l',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'd',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'u',\n",
       " 'b',\n",
       " 'r',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 's',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'z',\n",
       " 'o',\n",
       " 'e',\n",
       " '.',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'h',\n",
       " 'a',\n",
       " 'z',\n",
       " 'e',\n",
       " 'l',\n",
       " '.',\n",
       " 'v',\n",
       " 'i',\n",
       " 'o',\n",
       " 'l',\n",
       " 'e',\n",
       " 't',\n",
       " '.',\n",
       " 'a',\n",
       " 'u',\n",
       " 'r',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " '.',\n",
       " 's',\n",
       " 'a',\n",
       " 'v',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'a',\n",
       " 'u',\n",
       " 'd',\n",
       " 'r',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'b',\n",
       " 'r',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " '.',\n",
       " 'b',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'c',\n",
       " 'l',\n",
       " 'a',\n",
       " 'i',\n",
       " 'r',\n",
       " 'e',\n",
       " '.',\n",
       " 's',\n",
       " 'k',\n",
       " 'y',\n",
       " 'l',\n",
       " 'a',\n",
       " 'r',\n",
       " '.',\n",
       " 'l',\n",
       " 'u',\n",
       " 'c',\n",
       " 'y',\n",
       " '.',\n",
       " 'p',\n",
       " 'a',\n",
       " 'i',\n",
       " 's',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'e',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 'l',\n",
       " 'y',\n",
       " '.',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'c',\n",
       " 'a',\n",
       " 'r',\n",
       " 'o',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'n',\n",
       " 'o',\n",
       " 'v',\n",
       " 'a',\n",
       " '.',\n",
       " 'g',\n",
       " 'e',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " 'i',\n",
       " 's',\n",
       " '.',\n",
       " 'e',\n",
       " 'm',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " 'y',\n",
       " '.',\n",
       " 's',\n",
       " 'a',\n",
       " 'm',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " 'a',\n",
       " '.',\n",
       " 'w',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " '.',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'n',\n",
       " 'a',\n",
       " 'o',\n",
       " 'm',\n",
       " 'i',\n",
       " '.',\n",
       " 'a',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i',\n",
       " 'y',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 's',\n",
       " 'a',\n",
       " 'r',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'a',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " '.',\n",
       " 'g',\n",
       " 'a',\n",
       " 'b',\n",
       " 'r',\n",
       " 'i',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " '.',\n",
       " 'c',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " '.',\n",
       " 'r',\n",
       " 'u',\n",
       " 'b',\n",
       " 'y',\n",
       " '.',\n",
       " 'e',\n",
       " 'v',\n",
       " 'a',\n",
       " '.',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " 'i',\n",
       " 't',\n",
       " 'y',\n",
       " '.',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 'u',\n",
       " 'm',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'h',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'g',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'v',\n",
       " 'a',\n",
       " 'l',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'i',\n",
       " 's',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'q',\n",
       " 'u',\n",
       " 'i',\n",
       " 'n',\n",
       " 'n',\n",
       " '.',\n",
       " 'n',\n",
       " 'e',\n",
       " 'v',\n",
       " 'a',\n",
       " 'e',\n",
       " 'h',\n",
       " '.',\n",
       " 'i',\n",
       " 'v',\n",
       " 'y',\n",
       " '.',\n",
       " 's',\n",
       " 'a',\n",
       " 'd',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'p',\n",
       " 'i',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " '.',\n",
       " 'l',\n",
       " 'y',\n",
       " 'd',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'l',\n",
       " 'e',\n",
       " 'x',\n",
       " 'a',\n",
       " '.',\n",
       " 'j',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " 'p',\n",
       " 'h',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'e',\n",
       " 'm',\n",
       " 'e',\n",
       " 'r',\n",
       " 'y',\n",
       " '.',\n",
       " 'j',\n",
       " 'u',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'a',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'v',\n",
       " 'i',\n",
       " 'v',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " '.',\n",
       " 'k',\n",
       " 'a',\n",
       " 'y',\n",
       " 'l',\n",
       " 'e',\n",
       " 'e',\n",
       " '.',\n",
       " 's',\n",
       " 'o',\n",
       " 'p',\n",
       " 'h',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'b',\n",
       " 'r',\n",
       " 'i',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'p',\n",
       " 'e',\n",
       " 'y',\n",
       " 't',\n",
       " 'o',\n",
       " 'n',\n",
       " '.',\n",
       " 'r',\n",
       " 'y',\n",
       " 'l',\n",
       " 'e',\n",
       " 'e',\n",
       " '.',\n",
       " 'c',\n",
       " 'l',\n",
       " 'a',\n",
       " 'r',\n",
       " 'a',\n",
       " '.',\n",
       " 'h',\n",
       " 'a',\n",
       " 'd',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'm',\n",
       " 'e',\n",
       " 'l',\n",
       " 'a',\n",
       " 'n',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'c',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " 'z',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 'g',\n",
       " 'a',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'd',\n",
       " 'a',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " 'n',\n",
       " '.',\n",
       " 'l',\n",
       " 'i',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'u',\n",
       " 'b',\n",
       " 'r',\n",
       " 'e',\n",
       " 'e',\n",
       " '.',\n",
       " 'j',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " '.',\n",
       " 'k',\n",
       " 'a',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'b',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " '.',\n",
       " 'n',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'r',\n",
       " 'a',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " 'n',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'x',\n",
       " 'i',\n",
       " 'm',\n",
       " 'e',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " 'a',\n",
       " '.',\n",
       " 'l',\n",
       " 'e',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'n',\n",
       " 'i',\n",
       " '.',\n",
       " 't',\n",
       " 'a',\n",
       " 'y',\n",
       " 'l',\n",
       " 'o',\n",
       " 'r',\n",
       " '.',\n",
       " 'f',\n",
       " 'a',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " '.',\n",
       " 'r',\n",
       " 'o',\n",
       " 's',\n",
       " 'e',\n",
       " '.',\n",
       " 'k',\n",
       " 'y',\n",
       " 'l',\n",
       " 'i',\n",
       " 'e',\n",
       " '.',\n",
       " 'a',\n",
       " 'l',\n",
       " 'e',\n",
       " 'x',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'r',\n",
       " 'a',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " '.',\n",
       " 'm',\n",
       " 'a',\n",
       " 'r',\n",
       " 'g',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 't',\n",
       " '.',\n",
       " 'l',\n",
       " 'y',\n",
       " 'l',\n",
       " 'a',\n",
       " '.',\n",
       " 'a',\n",
       " 's',\n",
       " 'h',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'a',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " 'a',\n",
       " '.',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'z',\n",
       " 'a',\n",
       " '.',\n",
       " 'b',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " '.',\n",
       " 'b',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " '.',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " '.',\n",
       " 'k',\n",
       " 'h',\n",
       " 'l',\n",
       " 'o',\n",
       " 'e',\n",
       " '.',\n",
       " 'j',\n",
       " 'a',\n",
       " 's',\n",
       " 'm',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " '.',\n",
       " 'm',\n",
       " 'e',\n",
       " 'l',\n",
       " 'o',\n",
       " 'd',\n",
       " 'y',\n",
       " '.',\n",
       " 'i',\n",
       " 'r',\n",
       " 'i',\n",
       " 's',\n",
       " '.',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'b',\n",
       " 'e',\n",
       " 'l',\n",
       " '.',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 'a',\n",
       " 'h',\n",
       " '.',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'a',\n",
       " 'b',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " '.',\n",
       " 'v',\n",
       " 'a',\n",
       " 'l',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " '.',\n",
       " 'e',\n",
       " 'm',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " '.',\n",
       " 'a',\n",
       " 'd',\n",
       " 'a',\n",
       " 'l',\n",
       " 'y',\n",
       " 'n',\n",
       " '.',\n",
       " 'r',\n",
       " 'y',\n",
       " 'l',\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i if i != '\\n'else \".\" for i in list(name_r)] # Peak at letters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c9d004e-e5c8-49e9-80ea-3bdfde3dda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of each of these names\n",
    "names = str.split(name_r, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6fbe2c4-1d9c-4b8e-b4f8-4817c34267cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2095e54-297a-4b8f-a4f7-2f4e3bf016f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we are trying to build is a model that will use the Bigram model to predict the next likely character after a given character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d387a633-d105-4c7f-8c65-cb6d32d081e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's count how many times a given two bigram happen within our name dataset\n",
    "b = {}\n",
    "for char in names:\n",
    "    for i, j in zip(\"$\" + char, char + \"#\" ):  # $ is used to express start character or end character\n",
    "        if (i,j) in b: \n",
    "            b[(i,j)]+= 1\n",
    "        else: b[(i,j)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41153243-afe0-485c-85d8-2f79f934724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's count how many times a given two bigram happen within our name dataset\n",
    "b = {}\n",
    "for char in names:\n",
    "    for i, j in zip(\"$\" + char, char + \"#\" ):  # $ is used to express start character or end character\n",
    "        b[i,j] = b.get((i,j), 0) + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fad7d6c-bf9a-4ece-9c8b-94a03ffa31f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Order the dictionary\n",
    "b1 =  {}\n",
    "for i in sorted(b, key = b.get, reverse = True):  \n",
    "    b1[i] = b.get(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a3494e-b26c-4995-a16c-24d60f3aeacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('$', 'e'): 1531,\n",
       " ('e', 'm'): 769,\n",
       " ('m', 'm'): 168,\n",
       " ('m', 'a'): 2590,\n",
       " ('a', '#'): 6640,\n",
       " ('$', 'o'): 394,\n",
       " ('o', 'l'): 619,\n",
       " ('l', 'i'): 2480,\n",
       " ('i', 'v'): 269,\n",
       " ('v', 'i'): 911,\n",
       " ('i', 'a'): 2445,\n",
       " ('$', 'a'): 4410,\n",
       " ('a', 'v'): 834,\n",
       " ('v', 'a'): 642,\n",
       " ('$', 'i'): 591,\n",
       " ('i', 's'): 1316,\n",
       " ('s', 'a'): 1201,\n",
       " ('a', 'b'): 541,\n",
       " ('b', 'e'): 655,\n",
       " ('e', 'l'): 3248,\n",
       " ('l', 'l'): 1345,\n",
       " ('l', 'a'): 2623,\n",
       " ('$', 's'): 2055,\n",
       " ('s', 'o'): 531,\n",
       " ('o', 'p'): 95,\n",
       " ('p', 'h'): 204,\n",
       " ('h', 'i'): 729,\n",
       " ('$', 'c'): 1542,\n",
       " ('c', 'h'): 664,\n",
       " ('h', 'a'): 2244,\n",
       " ('a', 'r'): 3264,\n",
       " ('r', 'l'): 413,\n",
       " ('l', 'o'): 692,\n",
       " ('o', 't'): 118,\n",
       " ('t', 't'): 374,\n",
       " ('t', 'e'): 716,\n",
       " ('e', '#'): 3983,\n",
       " ('$', 'm'): 2538,\n",
       " ('m', 'i'): 1256,\n",
       " ('a', 'm'): 1634,\n",
       " ('m', 'e'): 818,\n",
       " ('$', 'h'): 874,\n",
       " ('r', 'p'): 14,\n",
       " ('p', 'e'): 197,\n",
       " ('e', 'r'): 1958,\n",
       " ('r', '#'): 1377,\n",
       " ('e', 'v'): 463,\n",
       " ('v', 'e'): 568,\n",
       " ('l', 'y'): 1588,\n",
       " ('y', 'n'): 1826,\n",
       " ('n', '#'): 6763,\n",
       " ('b', 'i'): 217,\n",
       " ('i', 'g'): 428,\n",
       " ('g', 'a'): 330,\n",
       " ('a', 'i'): 1650,\n",
       " ('i', 'l'): 1345,\n",
       " ('l', '#'): 1314,\n",
       " ('y', '#'): 2007,\n",
       " ('i', 'z'): 277,\n",
       " ('z', 'a'): 860,\n",
       " ('e', 't'): 580,\n",
       " ('t', 'h'): 647,\n",
       " ('h', '#'): 2409,\n",
       " ('r', 'y'): 773,\n",
       " ('o', 'f'): 34,\n",
       " ('f', 'i'): 160,\n",
       " ('c', 'a'): 815,\n",
       " ('r', 'i'): 3033,\n",
       " ('s', 'c'): 60,\n",
       " ('l', 'e'): 2921,\n",
       " ('t', '#'): 483,\n",
       " ('$', 'v'): 376,\n",
       " ('i', 'c'): 509,\n",
       " ('c', 't'): 35,\n",
       " ('t', 'o'): 667,\n",
       " ('o', 'r'): 1059,\n",
       " ('a', 'd'): 1042,\n",
       " ('d', 'i'): 674,\n",
       " ('o', 'n'): 2411,\n",
       " ('$', 'l'): 1572,\n",
       " ('l', 'u'): 324,\n",
       " ('u', 'n'): 275,\n",
       " ('n', 'a'): 2977,\n",
       " ('$', 'g'): 669,\n",
       " ('g', 'r'): 201,\n",
       " ('r', 'a'): 2356,\n",
       " ('a', 'c'): 470,\n",
       " ('c', 'e'): 551,\n",
       " ('h', 'l'): 185,\n",
       " ('o', 'e'): 132,\n",
       " ('$', 'p'): 515,\n",
       " ('e', 'n'): 2675,\n",
       " ('n', 'e'): 1359,\n",
       " ('a', 'y'): 2050,\n",
       " ('y', 'l'): 1104,\n",
       " ('$', 'r'): 1639,\n",
       " ('e', 'y'): 1070,\n",
       " ('$', 'z'): 929,\n",
       " ('z', 'o'): 110,\n",
       " ('$', 'n'): 1146,\n",
       " ('n', 'o'): 496,\n",
       " ('e', 'a'): 679,\n",
       " ('a', 'n'): 5438,\n",
       " ('n', 'n'): 1906,\n",
       " ('a', 'h'): 2332,\n",
       " ('d', 'd'): 149,\n",
       " ('a', 'u'): 381,\n",
       " ('u', 'b'): 103,\n",
       " ('b', 'r'): 842,\n",
       " ('r', 'e'): 1697,\n",
       " ('i', 'e'): 1653,\n",
       " ('s', 't'): 765,\n",
       " ('a', 't'): 687,\n",
       " ('t', 'a'): 1027,\n",
       " ('a', 'l'): 2528,\n",
       " ('a', 'z'): 435,\n",
       " ('z', 'e'): 373,\n",
       " ('i', 'o'): 588,\n",
       " ('u', 'r'): 414,\n",
       " ('r', 'o'): 869,\n",
       " ('u', 'd'): 136,\n",
       " ('d', 'r'): 424,\n",
       " ('$', 'b'): 1306,\n",
       " ('o', 'o'): 115,\n",
       " ('o', 'k'): 68,\n",
       " ('k', 'l'): 139,\n",
       " ('c', 'l'): 116,\n",
       " ('i', 'r'): 849,\n",
       " ('s', 'k'): 82,\n",
       " ('k', 'y'): 379,\n",
       " ('u', 'c'): 103,\n",
       " ('c', 'y'): 104,\n",
       " ('p', 'a'): 209,\n",
       " ('s', 'l'): 279,\n",
       " ('i', 'n'): 2126,\n",
       " ('o', 'v'): 176,\n",
       " ('g', 'e'): 334,\n",
       " ('e', 's'): 861,\n",
       " ('s', 'i'): 684,\n",
       " ('s', '#'): 1169,\n",
       " ('$', 'k'): 2963,\n",
       " ('k', 'e'): 895,\n",
       " ('e', 'd'): 384,\n",
       " ('d', 'y'): 317,\n",
       " ('n', 't'): 443,\n",
       " ('y', 'a'): 2143,\n",
       " ('$', 'w'): 307,\n",
       " ('w', 'i'): 148,\n",
       " ('o', 'w'): 114,\n",
       " ('w', '#'): 51,\n",
       " ('k', 'i'): 509,\n",
       " ('n', 's'): 278,\n",
       " ('a', 'o'): 63,\n",
       " ('o', 'm'): 261,\n",
       " ('i', '#'): 2489,\n",
       " ('a', 'a'): 556,\n",
       " ('i', 'y'): 779,\n",
       " ('d', 'e'): 1283,\n",
       " ('c', 'o'): 380,\n",
       " ('r', 'u'): 252,\n",
       " ('b', 'y'): 83,\n",
       " ('s', 'e'): 884,\n",
       " ('n', 'i'): 1725,\n",
       " ('i', 't'): 541,\n",
       " ('t', 'y'): 341,\n",
       " ('u', 't'): 82,\n",
       " ('t', 'u'): 78,\n",
       " ('u', 'm'): 154,\n",
       " ('m', 'n'): 20,\n",
       " ('g', 'i'): 190,\n",
       " ('t', 'i'): 532,\n",
       " ('$', 'q'): 92,\n",
       " ('q', 'u'): 206,\n",
       " ('u', 'i'): 121,\n",
       " ('a', 'e'): 692,\n",
       " ('e', 'h'): 152,\n",
       " ('v', 'y'): 121,\n",
       " ('p', 'i'): 61,\n",
       " ('i', 'p'): 53,\n",
       " ('y', 'd'): 272,\n",
       " ('e', 'x'): 132,\n",
       " ('x', 'a'): 103,\n",
       " ('$', 'j'): 2422,\n",
       " ('j', 'o'): 479,\n",
       " ('o', 's'): 504,\n",
       " ('e', 'p'): 83,\n",
       " ('j', 'u'): 202,\n",
       " ('u', 'l'): 301,\n",
       " ('$', 'd'): 1690,\n",
       " ('k', 'a'): 1731,\n",
       " ('e', 'e'): 1271,\n",
       " ('y', 't'): 104,\n",
       " ('d', 'l'): 60,\n",
       " ('c', 'k'): 316,\n",
       " ('n', 'z'): 145,\n",
       " ('z', 'i'): 364,\n",
       " ('a', 'g'): 168,\n",
       " ('d', 'a'): 1303,\n",
       " ('j', 'a'): 1473,\n",
       " ('h', 'e'): 674,\n",
       " ('$', 'x'): 134,\n",
       " ('x', 'i'): 102,\n",
       " ('i', 'm'): 427,\n",
       " ('e', 'i'): 818,\n",
       " ('$', 't'): 1308,\n",
       " ('$', 'f'): 417,\n",
       " ('f', 'a'): 242,\n",
       " ('n', 'd'): 704,\n",
       " ('r', 'g'): 76,\n",
       " ('a', 's'): 1118,\n",
       " ('s', 'h'): 1285,\n",
       " ('b', 'a'): 321,\n",
       " ('k', 'h'): 307,\n",
       " ('s', 'm'): 90,\n",
       " ('o', 'd'): 190,\n",
       " ('r', 's'): 190,\n",
       " ('g', 'h'): 360,\n",
       " ('s', 'y'): 215,\n",
       " ('y', 's'): 401,\n",
       " ('s', 's'): 461,\n",
       " ('e', 'c'): 153,\n",
       " ('c', 'i'): 271,\n",
       " ('m', 'o'): 452,\n",
       " ('r', 'k'): 90,\n",
       " ('n', 'l'): 195,\n",
       " ('d', 'n'): 31,\n",
       " ('r', 'd'): 187,\n",
       " ('o', 'i'): 69,\n",
       " ('t', 'r'): 352,\n",
       " ('m', 'b'): 112,\n",
       " ('r', 'm'): 162,\n",
       " ('n', 'y'): 465,\n",
       " ('d', 'o'): 378,\n",
       " ('o', 'a'): 149,\n",
       " ('o', 'c'): 114,\n",
       " ('m', 'y'): 287,\n",
       " ('s', 'u'): 185,\n",
       " ('m', 'c'): 51,\n",
       " ('p', 'r'): 151,\n",
       " ('o', 'u'): 275,\n",
       " ('r', 'n'): 140,\n",
       " ('w', 'a'): 280,\n",
       " ('e', 'b'): 121,\n",
       " ('c', 'c'): 42,\n",
       " ('a', 'w'): 161,\n",
       " ('w', 'y'): 73,\n",
       " ('y', 'e'): 301,\n",
       " ('e', 'o'): 269,\n",
       " ('a', 'k'): 568,\n",
       " ('n', 'g'): 273,\n",
       " ('k', 'o'): 344,\n",
       " ('b', 'l'): 103,\n",
       " ('h', 'o'): 287,\n",
       " ('e', 'g'): 125,\n",
       " ('f', 'r'): 114,\n",
       " ('s', 'p'): 51,\n",
       " ('l', 's'): 94,\n",
       " ('y', 'z'): 78,\n",
       " ('g', 'g'): 25,\n",
       " ('z', 'u'): 73,\n",
       " ('i', 'd'): 440,\n",
       " ('m', '#'): 516,\n",
       " ('o', 'g'): 44,\n",
       " ('j', 'e'): 440,\n",
       " ('g', 'n'): 27,\n",
       " ('y', 'r'): 291,\n",
       " ('c', '#'): 97,\n",
       " ('c', 'q'): 11,\n",
       " ('u', 'e'): 169,\n",
       " ('i', 'f'): 101,\n",
       " ('f', 'e'): 123,\n",
       " ('i', 'x'): 89,\n",
       " ('x', '#'): 164,\n",
       " ('o', 'y'): 103,\n",
       " ('g', 'o'): 83,\n",
       " ('g', 't'): 31,\n",
       " ('l', 't'): 77,\n",
       " ('g', 'w'): 26,\n",
       " ('w', 'e'): 149,\n",
       " ('l', 'd'): 138,\n",
       " ('a', 'p'): 82,\n",
       " ('h', 'n'): 138,\n",
       " ('t', 'l'): 134,\n",
       " ('m', 'r'): 97,\n",
       " ('n', 'c'): 213,\n",
       " ('l', 'b'): 52,\n",
       " ('i', 'k'): 445,\n",
       " ('$', 'y'): 535,\n",
       " ('t', 'z'): 105,\n",
       " ('h', 'r'): 204,\n",
       " ('j', 'i'): 119,\n",
       " ('h', 't'): 71,\n",
       " ('r', 'r'): 425,\n",
       " ('z', 'l'): 123,\n",
       " ('w', 'r'): 22,\n",
       " ('b', 'b'): 38,\n",
       " ('r', 't'): 208,\n",
       " ('l', 'v'): 72,\n",
       " ('e', 'j'): 55,\n",
       " ('o', 'h'): 171,\n",
       " ('u', 's'): 474,\n",
       " ('i', 'b'): 110,\n",
       " ('g', 'l'): 32,\n",
       " ('h', 'y'): 213,\n",
       " ('p', 'o'): 59,\n",
       " ('p', 'p'): 39,\n",
       " ('p', 'y'): 12,\n",
       " ('n', 'r'): 44,\n",
       " ('z', 'm'): 35,\n",
       " ('v', 'o'): 153,\n",
       " ('l', 'm'): 60,\n",
       " ('o', 'x'): 45,\n",
       " ('d', '#'): 516,\n",
       " ('i', 'u'): 109,\n",
       " ('v', '#'): 88,\n",
       " ('f', 'f'): 44,\n",
       " ('b', 'o'): 105,\n",
       " ('e', 'k'): 178,\n",
       " ('c', 'r'): 76,\n",
       " ('d', 'g'): 25,\n",
       " ('r', 'c'): 99,\n",
       " ('r', 'h'): 121,\n",
       " ('n', 'k'): 58,\n",
       " ('h', 'u'): 166,\n",
       " ('d', 's'): 29,\n",
       " ('a', 'x'): 182,\n",
       " ('y', 'c'): 115,\n",
       " ('e', 'w'): 50,\n",
       " ('v', 'k'): 3,\n",
       " ('z', 'h'): 43,\n",
       " ('w', 'h'): 23,\n",
       " ('t', 'n'): 22,\n",
       " ('x', 'l'): 39,\n",
       " ('g', 'u'): 85,\n",
       " ('u', 'a'): 163,\n",
       " ('u', 'p'): 16,\n",
       " ('u', 'g'): 47,\n",
       " ('d', 'u'): 92,\n",
       " ('l', 'c'): 25,\n",
       " ('r', 'b'): 41,\n",
       " ('a', 'q'): 60,\n",
       " ('b', '#'): 114,\n",
       " ('g', 'y'): 31,\n",
       " ('y', 'p'): 15,\n",
       " ('p', 't'): 17,\n",
       " ('e', 'z'): 181,\n",
       " ('z', 'r'): 32,\n",
       " ('f', 'l'): 20,\n",
       " ('o', '#'): 855,\n",
       " ('o', 'b'): 140,\n",
       " ('u', 'z'): 45,\n",
       " ('z', '#'): 160,\n",
       " ('i', 'q'): 52,\n",
       " ('y', 'v'): 106,\n",
       " ('n', 'v'): 55,\n",
       " ('d', 'h'): 118,\n",
       " ('g', 'd'): 19,\n",
       " ('t', 's'): 35,\n",
       " ('n', 'h'): 26,\n",
       " ('y', 'j'): 23,\n",
       " ('k', 'r'): 109,\n",
       " ('z', 'b'): 4,\n",
       " ('g', '#'): 108,\n",
       " ('a', 'j'): 175,\n",
       " ('r', 'j'): 25,\n",
       " ('m', 'p'): 38,\n",
       " ('p', 'b'): 2,\n",
       " ('y', 'o'): 271,\n",
       " ('z', 'y'): 147,\n",
       " ('p', 'l'): 16,\n",
       " ('l', 'k'): 24,\n",
       " ('i', 'j'): 76,\n",
       " ('x', 'e'): 36,\n",
       " ('y', 'u'): 141,\n",
       " ('l', 'n'): 14,\n",
       " ('u', 'x'): 34,\n",
       " ('i', 'h'): 95,\n",
       " ('w', 's'): 20,\n",
       " ('k', 's'): 95,\n",
       " ('m', 'u'): 139,\n",
       " ('y', 'k'): 86,\n",
       " ('e', 'f'): 82,\n",
       " ('k', '#'): 363,\n",
       " ('y', 'm'): 148,\n",
       " ('z', 'z'): 45,\n",
       " ('m', 'd'): 24,\n",
       " ('s', 'r'): 55,\n",
       " ('e', 'u'): 69,\n",
       " ('l', 'h'): 19,\n",
       " ('a', 'f'): 134,\n",
       " ('r', 'w'): 21,\n",
       " ('n', 'u'): 96,\n",
       " ('v', 'r'): 48,\n",
       " ('m', 's'): 35,\n",
       " ('$', 'u'): 78,\n",
       " ('f', 's'): 6,\n",
       " ('y', 'b'): 27,\n",
       " ('x', 'o'): 41,\n",
       " ('g', 's'): 30,\n",
       " ('x', 'y'): 30,\n",
       " ('w', 'n'): 58,\n",
       " ('j', 'h'): 45,\n",
       " ('f', 'n'): 4,\n",
       " ('n', 'j'): 44,\n",
       " ('r', 'v'): 80,\n",
       " ('n', 'm'): 19,\n",
       " ('t', 'c'): 17,\n",
       " ('s', 'w'): 24,\n",
       " ('k', 't'): 17,\n",
       " ('f', 't'): 18,\n",
       " ('x', 't'): 70,\n",
       " ('u', 'v'): 37,\n",
       " ('k', 'k'): 20,\n",
       " ('s', 'n'): 24,\n",
       " ('u', '#'): 155,\n",
       " ('j', 'r'): 11,\n",
       " ('y', 'x'): 28,\n",
       " ('h', 'm'): 117,\n",
       " ('e', 'q'): 14,\n",
       " ('u', 'o'): 10,\n",
       " ('f', '#'): 80,\n",
       " ('h', 'z'): 20,\n",
       " ('h', 'k'): 29,\n",
       " ('y', 'g'): 30,\n",
       " ('q', 'r'): 1,\n",
       " ('v', 'n'): 8,\n",
       " ('s', 'd'): 9,\n",
       " ('y', 'i'): 192,\n",
       " ('n', 'w'): 11,\n",
       " ('d', 'v'): 17,\n",
       " ('h', 'v'): 39,\n",
       " ('x', 'w'): 3,\n",
       " ('o', 'z'): 54,\n",
       " ('k', 'u'): 50,\n",
       " ('u', 'h'): 58,\n",
       " ('k', 'n'): 26,\n",
       " ('s', 'b'): 21,\n",
       " ('i', 'i'): 82,\n",
       " ('y', 'y'): 23,\n",
       " ('r', 'z'): 23,\n",
       " ('l', 'g'): 6,\n",
       " ('l', 'p'): 15,\n",
       " ('p', '#'): 33,\n",
       " ('b', 'u'): 45,\n",
       " ('f', 'u'): 10,\n",
       " ('b', 'h'): 41,\n",
       " ('f', 'y'): 14,\n",
       " ('u', 'w'): 86,\n",
       " ('x', 'u'): 5,\n",
       " ('q', '#'): 28,\n",
       " ('l', 'r'): 18,\n",
       " ('m', 'h'): 5,\n",
       " ('l', 'w'): 16,\n",
       " ('j', '#'): 71,\n",
       " ('s', 'v'): 14,\n",
       " ('m', 'l'): 5,\n",
       " ('n', 'f'): 11,\n",
       " ('u', 'j'): 14,\n",
       " ('f', 'o'): 60,\n",
       " ('j', 'l'): 9,\n",
       " ('t', 'g'): 2,\n",
       " ('j', 'm'): 5,\n",
       " ('v', 'v'): 7,\n",
       " ('p', 's'): 16,\n",
       " ('t', 'w'): 11,\n",
       " ('x', 'c'): 4,\n",
       " ('u', 'k'): 93,\n",
       " ('v', 'l'): 14,\n",
       " ('h', 'd'): 24,\n",
       " ('l', 'z'): 10,\n",
       " ('k', 'w'): 34,\n",
       " ('n', 'b'): 8,\n",
       " ('q', 's'): 2,\n",
       " ('i', 'w'): 8,\n",
       " ('c', 's'): 5,\n",
       " ('h', 's'): 31,\n",
       " ('m', 't'): 4,\n",
       " ('h', 'w'): 10,\n",
       " ('x', 'x'): 38,\n",
       " ('t', 'x'): 2,\n",
       " ('d', 'z'): 1,\n",
       " ('x', 'z'): 19,\n",
       " ('t', 'm'): 4,\n",
       " ('t', 'j'): 3,\n",
       " ('u', 'q'): 10,\n",
       " ('q', 'a'): 13,\n",
       " ('f', 'k'): 2,\n",
       " ('z', 'n'): 4,\n",
       " ('l', 'j'): 6,\n",
       " ('j', 'w'): 6,\n",
       " ('v', 'u'): 7,\n",
       " ('c', 'j'): 3,\n",
       " ('h', 'b'): 8,\n",
       " ('z', 't'): 4,\n",
       " ('p', 'u'): 4,\n",
       " ('m', 'z'): 11,\n",
       " ('x', 's'): 31,\n",
       " ('b', 't'): 2,\n",
       " ('u', 'y'): 13,\n",
       " ('d', 'j'): 9,\n",
       " ('j', 's'): 7,\n",
       " ('w', 'u'): 25,\n",
       " ('o', 'j'): 16,\n",
       " ('b', 's'): 8,\n",
       " ('d', 'w'): 23,\n",
       " ('w', 'o'): 36,\n",
       " ('j', 'n'): 2,\n",
       " ('w', 't'): 8,\n",
       " ('l', 'f'): 22,\n",
       " ('d', 'm'): 30,\n",
       " ('p', 'j'): 1,\n",
       " ('j', 'y'): 10,\n",
       " ('y', 'f'): 12,\n",
       " ('q', 'i'): 13,\n",
       " ('j', 'v'): 5,\n",
       " ('q', 'l'): 1,\n",
       " ('s', 'z'): 10,\n",
       " ('k', 'm'): 9,\n",
       " ('w', 'l'): 13,\n",
       " ('p', 'f'): 1,\n",
       " ('q', 'w'): 3,\n",
       " ('n', 'x'): 6,\n",
       " ('k', 'c'): 2,\n",
       " ('t', 'v'): 15,\n",
       " ('c', 'u'): 35,\n",
       " ('z', 'k'): 2,\n",
       " ('c', 'z'): 4,\n",
       " ('y', 'q'): 6,\n",
       " ('y', 'h'): 22,\n",
       " ('r', 'f'): 9,\n",
       " ('s', 'j'): 2,\n",
       " ('h', 'j'): 9,\n",
       " ('g', 'b'): 3,\n",
       " ('u', 'f'): 19,\n",
       " ('s', 'f'): 2,\n",
       " ('q', 'e'): 1,\n",
       " ('b', 'c'): 1,\n",
       " ('c', 'd'): 1,\n",
       " ('z', 'j'): 2,\n",
       " ('n', 'q'): 2,\n",
       " ('m', 'f'): 1,\n",
       " ('p', 'n'): 1,\n",
       " ('f', 'z'): 2,\n",
       " ('b', 'n'): 4,\n",
       " ('w', 'd'): 8,\n",
       " ('w', 'b'): 1,\n",
       " ('b', 'd'): 65,\n",
       " ('z', 's'): 4,\n",
       " ('p', 'c'): 1,\n",
       " ('h', 'g'): 2,\n",
       " ('m', 'j'): 7,\n",
       " ('w', 'w'): 2,\n",
       " ('k', 'j'): 2,\n",
       " ('h', 'p'): 1,\n",
       " ('j', 'k'): 2,\n",
       " ('o', 'q'): 3,\n",
       " ('f', 'w'): 4,\n",
       " ('f', 'h'): 1,\n",
       " ('w', 'm'): 2,\n",
       " ('b', 'j'): 1,\n",
       " ('r', 'q'): 16,\n",
       " ('z', 'c'): 2,\n",
       " ('z', 'v'): 2,\n",
       " ('f', 'g'): 1,\n",
       " ('n', 'p'): 5,\n",
       " ('z', 'g'): 1,\n",
       " ('d', 't'): 4,\n",
       " ('w', 'f'): 2,\n",
       " ('d', 'f'): 5,\n",
       " ('w', 'k'): 6,\n",
       " ('q', 'm'): 2,\n",
       " ('k', 'z'): 2,\n",
       " ('j', 'j'): 2,\n",
       " ('c', 'p'): 1,\n",
       " ('p', 'k'): 1,\n",
       " ('p', 'm'): 1,\n",
       " ('j', 'd'): 4,\n",
       " ('r', 'x'): 3,\n",
       " ('x', 'n'): 1,\n",
       " ('d', 'c'): 3,\n",
       " ('g', 'j'): 3,\n",
       " ('x', 'f'): 3,\n",
       " ('j', 'c'): 4,\n",
       " ('s', 'q'): 1,\n",
       " ('k', 'f'): 1,\n",
       " ('z', 'p'): 2,\n",
       " ('j', 't'): 2,\n",
       " ('k', 'b'): 2,\n",
       " ('m', 'k'): 1,\n",
       " ('m', 'w'): 2,\n",
       " ('x', 'h'): 1,\n",
       " ('h', 'f'): 2,\n",
       " ('x', 'd'): 5,\n",
       " ('y', 'w'): 4,\n",
       " ('z', 'w'): 3,\n",
       " ('d', 'k'): 3,\n",
       " ('c', 'g'): 2,\n",
       " ('u', 'u'): 3,\n",
       " ('t', 'f'): 2,\n",
       " ('g', 'm'): 6,\n",
       " ('m', 'v'): 3,\n",
       " ('c', 'x'): 3,\n",
       " ('h', 'c'): 2,\n",
       " ('g', 'f'): 1,\n",
       " ('q', 'o'): 2,\n",
       " ('l', 'q'): 3,\n",
       " ('v', 'b'): 1,\n",
       " ('j', 'p'): 1,\n",
       " ('k', 'd'): 2,\n",
       " ('g', 'z'): 1,\n",
       " ('v', 'd'): 1,\n",
       " ('d', 'b'): 1,\n",
       " ('v', 'h'): 1,\n",
       " ('k', 'v'): 2,\n",
       " ('h', 'h'): 1,\n",
       " ('s', 'g'): 2,\n",
       " ('g', 'v'): 1,\n",
       " ('d', 'q'): 1,\n",
       " ('x', 'b'): 1,\n",
       " ('w', 'z'): 1,\n",
       " ('h', 'q'): 1,\n",
       " ('j', 'b'): 1,\n",
       " ('z', 'd'): 2,\n",
       " ('x', 'm'): 1,\n",
       " ('w', 'g'): 1,\n",
       " ('t', 'b'): 1,\n",
       " ('z', 'x'): 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "233a802a-946b-4053-bfaf-4d972e5377d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of keeping these in a dictionary, we'll store the info in a 2d array\n",
    "# The first row will have have the characters that are first and the second row will have\n",
    "# characters happening second. At the intersection of each two letters we'll have the number of occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "802ea072-4eb9-46c6-bd8e-4b8e84936cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76e49af4-4531-4b18-8994-a11817125743",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"\"\n",
    "for i in names:\n",
    "    for ch in i:\n",
    "        char = char + i\n",
    "char= sorted(list(set(char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0565987a-6277-4b3c-beb3-ce31b8769d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspondence between letters and numbers\n",
    "stoi = {}\n",
    "for count, i in enumerate(char , start = 1):\n",
    "    stoi[i] = count\n",
    "\n",
    "stoi[\".\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64a714fa-2707-4425-8db1-51881ec510c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse correspondence from numbers to letters\n",
    "itox = {x: list(stoi.items())[x-1][0] for x in range(1,27)}\n",
    "itox[0] = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "362389d5-5b82-4161-97ba-854f84c45cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stoi.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66bdcd00-549b-4382-a005-9f0740200d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add the combination number (bigrams) in the tensor array\n",
    "n_ar = torch.zeros((27, 27), dtype = torch.int32)\n",
    "\n",
    "for char in names:\n",
    "    for i, j in zip(\".\" + char, char + \".\" ):  # $ is used to express start character or end character\n",
    "        i1 = stoi[i]\n",
    "        i2 = stoi[j]\n",
    "        n_ar[i1, i2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ff52367-7b0e-4a91-ab24-31d0d4a068c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_rows = n_ar.sum(1, keepdim = True) # get the sum (of columns) accross rows\n",
    "P = 1 + n_ar.float()\n",
    "P /= Sum_rows # Obtain the conditional probability distribution for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbc7afcb-beb4-4eb6-856c-41a774e3d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1218e-05, 1.3770e-01, 4.0802e-02, 4.8169e-02, 5.2789e-02, 4.7826e-02,\n",
       "         1.3049e-02, 2.0916e-02, 2.7316e-02, 1.8481e-02, 7.5641e-02, 9.2530e-02,\n",
       "         4.9106e-02, 7.9262e-02, 3.5807e-02, 1.2331e-02, 1.6108e-02, 2.9033e-03,\n",
       "         5.1197e-02, 6.4184e-02, 4.0864e-02, 2.4662e-03, 1.1769e-02, 9.6151e-03,\n",
       "         4.2144e-03, 1.6733e-02, 2.9033e-02],\n",
       "        [1.9599e-01, 1.6438e-02, 1.5995e-02, 1.3900e-02, 3.0781e-02, 2.0452e-02,\n",
       "         3.9841e-03, 4.9875e-03, 6.8851e-02, 4.8724e-02, 5.1940e-03, 1.6792e-02,\n",
       "         7.4635e-02, 4.8251e-02, 1.6051e-01, 1.8887e-03, 2.4495e-03, 1.8002e-03,\n",
       "         9.6355e-02, 3.3023e-02, 2.0304e-02, 1.1273e-02, 2.4642e-02, 4.7809e-03,\n",
       "         5.4006e-03, 6.0528e-02, 1.2867e-02],\n",
       "        [4.3478e-02, 1.2174e-01, 1.4745e-02, 7.5614e-04, 2.4953e-02, 2.4802e-01,\n",
       "         3.7807e-04, 3.7807e-04, 1.5879e-02, 8.2420e-02, 7.5614e-04, 3.7807e-04,\n",
       "         3.9319e-02, 3.7807e-04, 1.8904e-03, 4.0076e-02, 3.7807e-04, 3.7807e-04,\n",
       "         3.1871e-01, 3.4026e-03, 1.1342e-03, 1.7391e-02, 3.7807e-04, 3.7807e-04,\n",
       "         3.7807e-04, 3.1758e-02, 3.7807e-04],\n",
       "        [2.7746e-02, 2.3103e-01, 2.8313e-04, 1.2174e-02, 5.6625e-04, 1.5629e-01,\n",
       "         2.8313e-04, 8.4938e-04, 1.8828e-01, 7.7010e-02, 1.1325e-03, 8.9751e-02,\n",
       "         3.3126e-02, 2.8313e-04, 2.8313e-04, 1.0787e-01, 5.6625e-04, 3.3975e-03,\n",
       "         2.1801e-02, 1.6988e-03, 1.0193e-02, 1.0193e-02, 2.8313e-04, 2.8313e-04,\n",
       "         1.1325e-03, 2.9728e-02, 1.4156e-03],\n",
       "        [9.4068e-02, 2.3726e-01, 3.6390e-04, 7.2780e-04, 2.7293e-02, 2.3362e-01,\n",
       "         1.0917e-03, 4.7307e-03, 2.1652e-02, 1.2282e-01, 1.8195e-03, 7.2780e-04,\n",
       "         1.1099e-02, 5.6405e-03, 5.8224e-03, 6.8959e-02, 1.8195e-04, 3.6390e-04,\n",
       "         7.7329e-02, 5.4585e-03, 9.0975e-04, 1.6921e-02, 3.2751e-03, 4.3668e-03,\n",
       "         1.8195e-04, 5.7860e-02, 3.6390e-04],\n",
       "        [1.9507e-01, 3.3296e-02, 5.9737e-03, 7.5405e-03, 1.8851e-02, 6.2283e-02,\n",
       "         4.0640e-03, 6.1695e-03, 7.4916e-03, 4.0102e-02, 2.7420e-03, 8.7646e-03,\n",
       "         1.5909e-01, 3.7703e-02, 1.3103e-01, 1.3220e-02, 4.1130e-03, 7.3447e-04,\n",
       "         9.5921e-02, 4.2207e-02, 2.8448e-02, 3.4275e-03, 2.2719e-02, 2.4972e-03,\n",
       "         6.5123e-03, 5.2441e-02, 8.9115e-03],\n",
       "        [8.9503e-02, 2.6851e-01, 1.1050e-03, 1.1050e-03, 1.1050e-03, 1.3702e-01,\n",
       "         4.9724e-02, 2.2099e-03, 2.2099e-03, 1.7790e-01, 1.1050e-03, 3.3149e-03,\n",
       "         2.3204e-02, 1.1050e-03, 5.5249e-03, 6.7403e-02, 1.1050e-03, 1.1050e-03,\n",
       "         1.2707e-01, 7.7348e-03, 2.0994e-02, 1.2155e-02, 1.1050e-03, 5.5249e-03,\n",
       "         1.1050e-03, 1.6575e-02, 3.3149e-03],\n",
       "        [5.6565e-02, 1.7177e-01, 2.0758e-03, 5.1894e-04, 1.0379e-02, 1.7385e-01,\n",
       "         1.0379e-03, 1.3492e-02, 1.8734e-01, 9.9118e-02, 2.0758e-03, 5.1894e-04,\n",
       "         1.7125e-02, 3.6326e-03, 1.4530e-02, 4.3591e-02, 5.1894e-04, 5.1894e-04,\n",
       "         1.0483e-01, 1.6087e-02, 1.6606e-02, 4.4629e-02, 1.0379e-03, 1.4011e-02,\n",
       "         5.1894e-04, 1.6606e-02, 1.0379e-03],\n",
       "        [3.1644e-01, 2.9477e-01, 1.1817e-03, 3.9391e-04, 3.2826e-03, 8.8629e-02,\n",
       "         3.9391e-04, 3.9391e-04, 2.6261e-04, 9.5851e-02, 1.3130e-03, 3.9391e-03,\n",
       "         2.4422e-02, 1.5494e-02, 1.8251e-02, 3.7815e-02, 2.6261e-04, 2.6261e-04,\n",
       "         2.6917e-02, 4.2017e-03, 9.4538e-03, 2.1928e-02, 5.2521e-03, 1.4443e-03,\n",
       "         1.3130e-04, 2.8099e-02, 2.7574e-03],\n",
       "        [1.4067e-01, 1.3818e-01, 6.2708e-03, 2.8812e-02, 2.4914e-02, 9.3441e-02,\n",
       "         5.7624e-03, 2.4236e-02, 5.4234e-03, 4.6890e-03, 4.3500e-03, 2.5196e-02,\n",
       "         7.6041e-02, 2.4179e-02, 1.2016e-01, 3.3275e-02, 3.0507e-03, 2.9942e-03,\n",
       "         4.8020e-02, 7.4403e-02, 3.0620e-02, 6.2143e-03, 1.5253e-02, 5.0845e-04,\n",
       "         5.0845e-03, 4.4065e-02, 1.5705e-02],\n",
       "        [2.4828e-02, 5.0828e-01, 6.8966e-04, 1.7241e-03, 1.7241e-03, 1.5207e-01,\n",
       "         3.4483e-04, 3.4483e-04, 1.5862e-02, 4.1379e-02, 1.0345e-03, 1.0345e-03,\n",
       "         3.4483e-03, 2.0690e-03, 1.0345e-03, 1.6552e-01, 6.8966e-04, 3.4483e-04,\n",
       "         4.1379e-03, 2.7586e-03, 1.0345e-03, 7.0000e-02, 2.0690e-03, 2.4138e-03,\n",
       "         3.4483e-04, 3.7931e-03, 3.4483e-04],\n",
       "        [7.2222e-02, 3.4365e-01, 5.9524e-04, 5.9524e-04, 5.9524e-04, 1.7778e-01,\n",
       "         3.9683e-04, 1.9841e-04, 6.1111e-02, 1.0119e-01, 5.9524e-04, 4.1667e-03,\n",
       "         2.7778e-02, 1.9841e-03, 5.3571e-03, 6.8452e-02, 1.9841e-04, 1.9841e-04,\n",
       "         2.1825e-02, 1.9048e-02, 3.5714e-03, 1.0119e-02, 5.9524e-04, 6.9444e-03,\n",
       "         1.9841e-04, 7.5397e-02, 5.9524e-04],\n",
       "        [9.4211e-02, 1.8799e-01, 3.7971e-03, 1.8627e-03, 9.9584e-03, 2.0934e-01,\n",
       "         1.6478e-03, 5.0150e-04, 1.4329e-03, 1.7775e-01, 5.0150e-04, 1.7911e-03,\n",
       "         9.6432e-02, 4.3703e-03, 1.0747e-03, 4.9649e-02, 1.1463e-03, 2.8657e-04,\n",
       "         1.3612e-03, 6.8061e-03, 5.5882e-03, 2.3284e-02, 5.2300e-03, 1.2179e-03,\n",
       "         7.1644e-05, 1.1384e-01, 7.8808e-04],\n",
       "        [7.7838e-02, 3.9009e-01, 1.7013e-02, 7.8290e-03, 3.7639e-03, 1.2331e-01,\n",
       "         3.0111e-04, 1.5056e-04, 9.0334e-04, 1.8925e-01, 1.2045e-03, 3.0111e-04,\n",
       "         9.0334e-04, 2.5444e-02, 3.1617e-03, 6.8202e-02, 5.8717e-03, 1.5056e-04,\n",
       "         1.4755e-02, 5.4201e-03, 7.5279e-04, 2.1078e-02, 6.0223e-04, 4.5167e-04,\n",
       "         1.5056e-04, 4.3360e-02, 1.8067e-03],\n",
       "        [3.6907e-01, 1.6249e-01, 4.9108e-04, 1.1677e-02, 3.8468e-02, 7.4207e-02,\n",
       "         6.5477e-04, 1.4951e-02, 1.4732e-03, 9.4178e-02, 2.4554e-03, 3.2193e-03,\n",
       "         1.0695e-02, 1.0913e-03, 1.0405e-01, 2.7118e-02, 3.2739e-04, 1.6369e-04,\n",
       "         2.4554e-03, 1.5223e-02, 2.4227e-02, 5.2927e-03, 3.0556e-03, 6.5477e-04,\n",
       "         3.8195e-04, 2.5427e-02, 7.9664e-03],\n",
       "        [1.0789e-01, 1.8906e-02, 1.7772e-02, 1.4495e-02, 2.4074e-02, 1.6763e-02,\n",
       "         4.4114e-03, 5.6718e-03, 2.1679e-02, 8.8228e-03, 2.1427e-03, 8.6967e-03,\n",
       "         7.8145e-02, 3.3022e-02, 3.0401e-01, 1.4621e-02, 1.2100e-02, 5.0416e-04,\n",
       "         1.3360e-01, 6.3650e-02, 1.4999e-02, 3.4787e-02, 2.2309e-02, 1.4495e-02,\n",
       "         5.7978e-03, 1.3108e-02, 6.9322e-03],\n",
       "        [3.3138e-02, 2.0468e-01, 2.9240e-03, 1.9493e-03, 9.7466e-04, 1.9298e-01,\n",
       "         1.9493e-03, 9.7466e-04, 1.9981e-01, 6.0429e-02, 1.9493e-03, 1.9493e-03,\n",
       "         1.6569e-02, 1.9493e-03, 1.9493e-03, 5.8480e-02, 3.8986e-02, 9.7466e-04,\n",
       "         1.4815e-01, 1.6569e-02, 1.7544e-02, 4.8733e-03, 9.7466e-04, 9.7466e-04,\n",
       "         9.7466e-04, 1.2671e-02, 9.7466e-04],\n",
       "        [1.0662e-01, 5.1471e-02, 3.6765e-03, 3.6765e-03, 3.6765e-03, 7.3529e-03,\n",
       "         3.6765e-03, 3.6765e-03, 3.6765e-03, 5.1471e-02, 3.6765e-03, 3.6765e-03,\n",
       "         7.3529e-03, 1.1029e-02, 3.6765e-03, 1.1029e-02, 3.6765e-03, 3.6765e-03,\n",
       "         7.3529e-03, 1.1029e-02, 3.6765e-03, 7.6103e-01, 3.6765e-03, 1.4706e-02,\n",
       "         3.6765e-03, 3.6765e-03, 3.6765e-03],\n",
       "        [1.0850e-01, 1.8559e-01, 3.3071e-03, 7.8740e-03, 1.4803e-02, 1.3370e-01,\n",
       "         7.8740e-04, 6.0630e-03, 9.6063e-03, 2.3890e-01, 2.0472e-03, 7.1654e-03,\n",
       "         3.2598e-02, 1.2835e-02, 1.1102e-02, 6.8504e-02, 1.1811e-03, 1.3386e-03,\n",
       "         3.3543e-02, 1.5039e-02, 1.6457e-02, 1.9921e-02, 6.3780e-03, 1.7323e-03,\n",
       "         3.1496e-04, 6.0945e-02, 1.8898e-03],\n",
       "        [1.4434e-01, 1.4829e-01, 2.7140e-03, 7.5253e-03, 1.2337e-03, 1.0918e-01,\n",
       "         3.7010e-04, 3.7010e-04, 1.5865e-01, 8.4505e-02, 3.7010e-04, 1.0239e-02,\n",
       "         3.4542e-02, 1.1226e-02, 3.0841e-03, 6.5630e-02, 6.4150e-03, 2.4673e-04,\n",
       "         6.9085e-03, 5.6995e-02, 9.4498e-02, 2.2946e-02, 1.8505e-03, 3.0841e-03,\n",
       "         1.2337e-04, 2.6647e-02, 1.3570e-03],\n",
       "        [8.6894e-02, 1.8456e-01, 3.5907e-04, 3.2316e-03, 1.7953e-04, 1.2873e-01,\n",
       "         5.3860e-04, 5.3860e-04, 1.1634e-01, 9.5691e-02, 7.1813e-04, 1.7953e-04,\n",
       "         2.4237e-02, 8.9767e-04, 4.1293e-03, 1.1993e-01, 1.7953e-04, 1.7953e-04,\n",
       "         6.3375e-02, 6.4632e-03, 6.7325e-02, 1.4183e-02, 2.8725e-03, 2.1544e-03,\n",
       "         5.3860e-04, 6.1400e-02, 1.9031e-02],\n",
       "        [4.9761e-02, 5.2313e-02, 3.3174e-02, 3.3174e-02, 4.3700e-02, 5.4226e-02,\n",
       "         6.3796e-03, 1.5311e-02, 1.8820e-02, 3.8915e-02, 4.7847e-03, 2.9984e-02,\n",
       "         9.6332e-02, 4.9442e-02, 8.8038e-02, 3.5088e-03, 5.4226e-03, 3.5088e-03,\n",
       "         1.3238e-01, 1.5152e-01, 2.6475e-02, 1.2759e-03, 1.2121e-02, 2.7751e-02,\n",
       "         1.1164e-02, 4.4657e-03, 1.4673e-02],\n",
       "        [3.4590e-02, 2.4990e-01, 7.7730e-04, 3.8865e-04, 7.7730e-04, 2.2114e-01,\n",
       "         3.8865e-04, 3.8865e-04, 7.7730e-04, 3.5445e-01, 3.8865e-04, 1.5546e-03,\n",
       "         5.8298e-03, 3.8865e-04, 3.4979e-03, 5.9852e-02, 3.8865e-04, 3.8865e-04,\n",
       "         1.9044e-02, 3.8865e-04, 3.8865e-04, 3.1092e-03, 3.1092e-03, 3.8865e-04,\n",
       "         3.8865e-04, 4.7415e-02, 3.8865e-04],\n",
       "        [5.5974e-02, 3.0248e-01, 2.1529e-03, 1.0764e-03, 9.6878e-03, 1.6146e-01,\n",
       "         3.2293e-03, 2.1529e-03, 2.5834e-02, 1.6039e-01, 1.0764e-03, 7.5350e-03,\n",
       "         1.5070e-02, 3.2293e-03, 6.3509e-02, 3.9828e-02, 1.0764e-03, 1.0764e-03,\n",
       "         2.4758e-02, 2.2605e-02, 9.6878e-03, 2.7987e-02, 1.0764e-03, 3.2293e-03,\n",
       "         1.0764e-03, 7.9656e-02, 2.1529e-03],\n",
       "        [2.3673e-01, 1.4921e-01, 2.8694e-03, 7.1736e-03, 8.6083e-03, 5.3085e-02,\n",
       "         5.7389e-03, 1.4347e-03, 2.8694e-03, 1.4778e-01, 1.4347e-03, 1.4347e-03,\n",
       "         5.7389e-02, 2.8694e-03, 2.8694e-03, 6.0258e-02, 1.4347e-03, 1.4347e-03,\n",
       "         1.4347e-03, 4.5911e-02, 1.0187e-01, 8.6083e-03, 1.4347e-03, 5.7389e-03,\n",
       "         5.5954e-02, 4.4476e-02, 2.8694e-02],\n",
       "        [2.0540e-01, 2.1931e-01, 2.8642e-03, 1.1866e-02, 2.7926e-02, 3.0892e-02,\n",
       "         1.3298e-03, 3.1710e-03, 2.3527e-03, 1.9742e-02, 2.4550e-03, 8.8993e-03,\n",
       "         1.1303e-01, 1.5241e-02, 1.8689e-01, 2.7823e-02, 1.6367e-03, 7.1604e-04,\n",
       "         2.9869e-02, 4.1121e-02, 1.0741e-02, 1.4525e-02, 1.0945e-02, 5.1146e-04,\n",
       "         2.9664e-03, 2.4550e-03, 8.0810e-03],\n",
       "        [6.7139e-02, 3.5905e-01, 2.0851e-03, 1.2510e-03, 1.2510e-03, 1.5596e-01,\n",
       "         4.1701e-04, 8.3403e-04, 1.8349e-02, 1.5221e-01, 1.2510e-03, 1.2510e-03,\n",
       "         5.1710e-02, 1.5013e-02, 2.0851e-03, 4.6289e-02, 1.2510e-03, 4.1701e-04,\n",
       "         1.3761e-02, 2.0851e-03, 2.0851e-03, 3.0859e-02, 1.2510e-03, 1.6681e-03,\n",
       "         8.3403e-04, 6.1718e-02, 1.9183e-02]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d75bdb0-06c8-4416-955a-e66e2da16dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilemaniehen.\n",
      "jaselyatt.\n",
      "abremin.\n",
      "modaweroboslyourina.\n",
      "gus.\n",
      "zusienamaynonisanercl.\n",
      "kren.\n",
      "ahaeiblienin.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(21483645)\n",
    "for j in range(8):\n",
    "    output  = []\n",
    "    ch_i = 0 # character under its number form\n",
    "    while True:\n",
    "        p = P[ch_i] # This is the conditional probability on chx, ie the probability distribution of potential follow ups given chx is the preceding character\n",
    "        ch_i = torch.multinomial(p, num_samples = 1, replacement =True, generator = g).item()\n",
    "        output.append(itox[ch_i])\n",
    "        if ch_i == 0 :\n",
    "            print(\"\".join(output))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cf622-328e-404c-8bc7-c2a460dfbf88",
   "metadata": {},
   "source": [
    "#### Evaluate the quality of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ab7230d-c93f-477d-a9c4-1ebbdaa7120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1218e-05, 1.3770e-01, 4.0802e-02, 4.8169e-02, 5.2789e-02, 4.7826e-02,\n",
       "         1.3049e-02, 2.0916e-02, 2.7316e-02, 1.8481e-02, 7.5641e-02, 9.2530e-02,\n",
       "         4.9106e-02, 7.9262e-02, 3.5807e-02, 1.2331e-02, 1.6108e-02, 2.9033e-03,\n",
       "         5.1197e-02, 6.4184e-02, 4.0864e-02, 2.4662e-03, 1.1769e-02, 9.6151e-03,\n",
       "         4.2144e-03, 1.6733e-02, 2.9033e-02],\n",
       "        [1.9599e-01, 1.6438e-02, 1.5995e-02, 1.3900e-02, 3.0781e-02, 2.0452e-02,\n",
       "         3.9841e-03, 4.9875e-03, 6.8851e-02, 4.8724e-02, 5.1940e-03, 1.6792e-02,\n",
       "         7.4635e-02, 4.8251e-02, 1.6051e-01, 1.8887e-03, 2.4495e-03, 1.8002e-03,\n",
       "         9.6355e-02, 3.3023e-02, 2.0304e-02, 1.1273e-02, 2.4642e-02, 4.7809e-03,\n",
       "         5.4006e-03, 6.0528e-02, 1.2867e-02],\n",
       "        [4.3478e-02, 1.2174e-01, 1.4745e-02, 7.5614e-04, 2.4953e-02, 2.4802e-01,\n",
       "         3.7807e-04, 3.7807e-04, 1.5879e-02, 8.2420e-02, 7.5614e-04, 3.7807e-04,\n",
       "         3.9319e-02, 3.7807e-04, 1.8904e-03, 4.0076e-02, 3.7807e-04, 3.7807e-04,\n",
       "         3.1871e-01, 3.4026e-03, 1.1342e-03, 1.7391e-02, 3.7807e-04, 3.7807e-04,\n",
       "         3.7807e-04, 3.1758e-02, 3.7807e-04],\n",
       "        [2.7746e-02, 2.3103e-01, 2.8313e-04, 1.2174e-02, 5.6625e-04, 1.5629e-01,\n",
       "         2.8313e-04, 8.4938e-04, 1.8828e-01, 7.7010e-02, 1.1325e-03, 8.9751e-02,\n",
       "         3.3126e-02, 2.8313e-04, 2.8313e-04, 1.0787e-01, 5.6625e-04, 3.3975e-03,\n",
       "         2.1801e-02, 1.6988e-03, 1.0193e-02, 1.0193e-02, 2.8313e-04, 2.8313e-04,\n",
       "         1.1325e-03, 2.9728e-02, 1.4156e-03],\n",
       "        [9.4068e-02, 2.3726e-01, 3.6390e-04, 7.2780e-04, 2.7293e-02, 2.3362e-01,\n",
       "         1.0917e-03, 4.7307e-03, 2.1652e-02, 1.2282e-01, 1.8195e-03, 7.2780e-04,\n",
       "         1.1099e-02, 5.6405e-03, 5.8224e-03, 6.8959e-02, 1.8195e-04, 3.6390e-04,\n",
       "         7.7329e-02, 5.4585e-03, 9.0975e-04, 1.6921e-02, 3.2751e-03, 4.3668e-03,\n",
       "         1.8195e-04, 5.7860e-02, 3.6390e-04],\n",
       "        [1.9507e-01, 3.3296e-02, 5.9737e-03, 7.5405e-03, 1.8851e-02, 6.2283e-02,\n",
       "         4.0640e-03, 6.1695e-03, 7.4916e-03, 4.0102e-02, 2.7420e-03, 8.7646e-03,\n",
       "         1.5909e-01, 3.7703e-02, 1.3103e-01, 1.3220e-02, 4.1130e-03, 7.3447e-04,\n",
       "         9.5921e-02, 4.2207e-02, 2.8448e-02, 3.4275e-03, 2.2719e-02, 2.4972e-03,\n",
       "         6.5123e-03, 5.2441e-02, 8.9115e-03],\n",
       "        [8.9503e-02, 2.6851e-01, 1.1050e-03, 1.1050e-03, 1.1050e-03, 1.3702e-01,\n",
       "         4.9724e-02, 2.2099e-03, 2.2099e-03, 1.7790e-01, 1.1050e-03, 3.3149e-03,\n",
       "         2.3204e-02, 1.1050e-03, 5.5249e-03, 6.7403e-02, 1.1050e-03, 1.1050e-03,\n",
       "         1.2707e-01, 7.7348e-03, 2.0994e-02, 1.2155e-02, 1.1050e-03, 5.5249e-03,\n",
       "         1.1050e-03, 1.6575e-02, 3.3149e-03],\n",
       "        [5.6565e-02, 1.7177e-01, 2.0758e-03, 5.1894e-04, 1.0379e-02, 1.7385e-01,\n",
       "         1.0379e-03, 1.3492e-02, 1.8734e-01, 9.9118e-02, 2.0758e-03, 5.1894e-04,\n",
       "         1.7125e-02, 3.6326e-03, 1.4530e-02, 4.3591e-02, 5.1894e-04, 5.1894e-04,\n",
       "         1.0483e-01, 1.6087e-02, 1.6606e-02, 4.4629e-02, 1.0379e-03, 1.4011e-02,\n",
       "         5.1894e-04, 1.6606e-02, 1.0379e-03],\n",
       "        [3.1644e-01, 2.9477e-01, 1.1817e-03, 3.9391e-04, 3.2826e-03, 8.8629e-02,\n",
       "         3.9391e-04, 3.9391e-04, 2.6261e-04, 9.5851e-02, 1.3130e-03, 3.9391e-03,\n",
       "         2.4422e-02, 1.5494e-02, 1.8251e-02, 3.7815e-02, 2.6261e-04, 2.6261e-04,\n",
       "         2.6917e-02, 4.2017e-03, 9.4538e-03, 2.1928e-02, 5.2521e-03, 1.4443e-03,\n",
       "         1.3130e-04, 2.8099e-02, 2.7574e-03],\n",
       "        [1.4067e-01, 1.3818e-01, 6.2708e-03, 2.8812e-02, 2.4914e-02, 9.3441e-02,\n",
       "         5.7624e-03, 2.4236e-02, 5.4234e-03, 4.6890e-03, 4.3500e-03, 2.5196e-02,\n",
       "         7.6041e-02, 2.4179e-02, 1.2016e-01, 3.3275e-02, 3.0507e-03, 2.9942e-03,\n",
       "         4.8020e-02, 7.4403e-02, 3.0620e-02, 6.2143e-03, 1.5253e-02, 5.0845e-04,\n",
       "         5.0845e-03, 4.4065e-02, 1.5705e-02],\n",
       "        [2.4828e-02, 5.0828e-01, 6.8966e-04, 1.7241e-03, 1.7241e-03, 1.5207e-01,\n",
       "         3.4483e-04, 3.4483e-04, 1.5862e-02, 4.1379e-02, 1.0345e-03, 1.0345e-03,\n",
       "         3.4483e-03, 2.0690e-03, 1.0345e-03, 1.6552e-01, 6.8966e-04, 3.4483e-04,\n",
       "         4.1379e-03, 2.7586e-03, 1.0345e-03, 7.0000e-02, 2.0690e-03, 2.4138e-03,\n",
       "         3.4483e-04, 3.7931e-03, 3.4483e-04],\n",
       "        [7.2222e-02, 3.4365e-01, 5.9524e-04, 5.9524e-04, 5.9524e-04, 1.7778e-01,\n",
       "         3.9683e-04, 1.9841e-04, 6.1111e-02, 1.0119e-01, 5.9524e-04, 4.1667e-03,\n",
       "         2.7778e-02, 1.9841e-03, 5.3571e-03, 6.8452e-02, 1.9841e-04, 1.9841e-04,\n",
       "         2.1825e-02, 1.9048e-02, 3.5714e-03, 1.0119e-02, 5.9524e-04, 6.9444e-03,\n",
       "         1.9841e-04, 7.5397e-02, 5.9524e-04],\n",
       "        [9.4211e-02, 1.8799e-01, 3.7971e-03, 1.8627e-03, 9.9584e-03, 2.0934e-01,\n",
       "         1.6478e-03, 5.0150e-04, 1.4329e-03, 1.7775e-01, 5.0150e-04, 1.7911e-03,\n",
       "         9.6432e-02, 4.3703e-03, 1.0747e-03, 4.9649e-02, 1.1463e-03, 2.8657e-04,\n",
       "         1.3612e-03, 6.8061e-03, 5.5882e-03, 2.3284e-02, 5.2300e-03, 1.2179e-03,\n",
       "         7.1644e-05, 1.1384e-01, 7.8808e-04],\n",
       "        [7.7838e-02, 3.9009e-01, 1.7013e-02, 7.8290e-03, 3.7639e-03, 1.2331e-01,\n",
       "         3.0111e-04, 1.5056e-04, 9.0334e-04, 1.8925e-01, 1.2045e-03, 3.0111e-04,\n",
       "         9.0334e-04, 2.5444e-02, 3.1617e-03, 6.8202e-02, 5.8717e-03, 1.5056e-04,\n",
       "         1.4755e-02, 5.4201e-03, 7.5279e-04, 2.1078e-02, 6.0223e-04, 4.5167e-04,\n",
       "         1.5056e-04, 4.3360e-02, 1.8067e-03],\n",
       "        [3.6907e-01, 1.6249e-01, 4.9108e-04, 1.1677e-02, 3.8468e-02, 7.4207e-02,\n",
       "         6.5477e-04, 1.4951e-02, 1.4732e-03, 9.4178e-02, 2.4554e-03, 3.2193e-03,\n",
       "         1.0695e-02, 1.0913e-03, 1.0405e-01, 2.7118e-02, 3.2739e-04, 1.6369e-04,\n",
       "         2.4554e-03, 1.5223e-02, 2.4227e-02, 5.2927e-03, 3.0556e-03, 6.5477e-04,\n",
       "         3.8195e-04, 2.5427e-02, 7.9664e-03],\n",
       "        [1.0789e-01, 1.8906e-02, 1.7772e-02, 1.4495e-02, 2.4074e-02, 1.6763e-02,\n",
       "         4.4114e-03, 5.6718e-03, 2.1679e-02, 8.8228e-03, 2.1427e-03, 8.6967e-03,\n",
       "         7.8145e-02, 3.3022e-02, 3.0401e-01, 1.4621e-02, 1.2100e-02, 5.0416e-04,\n",
       "         1.3360e-01, 6.3650e-02, 1.4999e-02, 3.4787e-02, 2.2309e-02, 1.4495e-02,\n",
       "         5.7978e-03, 1.3108e-02, 6.9322e-03],\n",
       "        [3.3138e-02, 2.0468e-01, 2.9240e-03, 1.9493e-03, 9.7466e-04, 1.9298e-01,\n",
       "         1.9493e-03, 9.7466e-04, 1.9981e-01, 6.0429e-02, 1.9493e-03, 1.9493e-03,\n",
       "         1.6569e-02, 1.9493e-03, 1.9493e-03, 5.8480e-02, 3.8986e-02, 9.7466e-04,\n",
       "         1.4815e-01, 1.6569e-02, 1.7544e-02, 4.8733e-03, 9.7466e-04, 9.7466e-04,\n",
       "         9.7466e-04, 1.2671e-02, 9.7466e-04],\n",
       "        [1.0662e-01, 5.1471e-02, 3.6765e-03, 3.6765e-03, 3.6765e-03, 7.3529e-03,\n",
       "         3.6765e-03, 3.6765e-03, 3.6765e-03, 5.1471e-02, 3.6765e-03, 3.6765e-03,\n",
       "         7.3529e-03, 1.1029e-02, 3.6765e-03, 1.1029e-02, 3.6765e-03, 3.6765e-03,\n",
       "         7.3529e-03, 1.1029e-02, 3.6765e-03, 7.6103e-01, 3.6765e-03, 1.4706e-02,\n",
       "         3.6765e-03, 3.6765e-03, 3.6765e-03],\n",
       "        [1.0850e-01, 1.8559e-01, 3.3071e-03, 7.8740e-03, 1.4803e-02, 1.3370e-01,\n",
       "         7.8740e-04, 6.0630e-03, 9.6063e-03, 2.3890e-01, 2.0472e-03, 7.1654e-03,\n",
       "         3.2598e-02, 1.2835e-02, 1.1102e-02, 6.8504e-02, 1.1811e-03, 1.3386e-03,\n",
       "         3.3543e-02, 1.5039e-02, 1.6457e-02, 1.9921e-02, 6.3780e-03, 1.7323e-03,\n",
       "         3.1496e-04, 6.0945e-02, 1.8898e-03],\n",
       "        [1.4434e-01, 1.4829e-01, 2.7140e-03, 7.5253e-03, 1.2337e-03, 1.0918e-01,\n",
       "         3.7010e-04, 3.7010e-04, 1.5865e-01, 8.4505e-02, 3.7010e-04, 1.0239e-02,\n",
       "         3.4542e-02, 1.1226e-02, 3.0841e-03, 6.5630e-02, 6.4150e-03, 2.4673e-04,\n",
       "         6.9085e-03, 5.6995e-02, 9.4498e-02, 2.2946e-02, 1.8505e-03, 3.0841e-03,\n",
       "         1.2337e-04, 2.6647e-02, 1.3570e-03],\n",
       "        [8.6894e-02, 1.8456e-01, 3.5907e-04, 3.2316e-03, 1.7953e-04, 1.2873e-01,\n",
       "         5.3860e-04, 5.3860e-04, 1.1634e-01, 9.5691e-02, 7.1813e-04, 1.7953e-04,\n",
       "         2.4237e-02, 8.9767e-04, 4.1293e-03, 1.1993e-01, 1.7953e-04, 1.7953e-04,\n",
       "         6.3375e-02, 6.4632e-03, 6.7325e-02, 1.4183e-02, 2.8725e-03, 2.1544e-03,\n",
       "         5.3860e-04, 6.1400e-02, 1.9031e-02],\n",
       "        [4.9761e-02, 5.2313e-02, 3.3174e-02, 3.3174e-02, 4.3700e-02, 5.4226e-02,\n",
       "         6.3796e-03, 1.5311e-02, 1.8820e-02, 3.8915e-02, 4.7847e-03, 2.9984e-02,\n",
       "         9.6332e-02, 4.9442e-02, 8.8038e-02, 3.5088e-03, 5.4226e-03, 3.5088e-03,\n",
       "         1.3238e-01, 1.5152e-01, 2.6475e-02, 1.2759e-03, 1.2121e-02, 2.7751e-02,\n",
       "         1.1164e-02, 4.4657e-03, 1.4673e-02],\n",
       "        [3.4590e-02, 2.4990e-01, 7.7730e-04, 3.8865e-04, 7.7730e-04, 2.2114e-01,\n",
       "         3.8865e-04, 3.8865e-04, 7.7730e-04, 3.5445e-01, 3.8865e-04, 1.5546e-03,\n",
       "         5.8298e-03, 3.8865e-04, 3.4979e-03, 5.9852e-02, 3.8865e-04, 3.8865e-04,\n",
       "         1.9044e-02, 3.8865e-04, 3.8865e-04, 3.1092e-03, 3.1092e-03, 3.8865e-04,\n",
       "         3.8865e-04, 4.7415e-02, 3.8865e-04],\n",
       "        [5.5974e-02, 3.0248e-01, 2.1529e-03, 1.0764e-03, 9.6878e-03, 1.6146e-01,\n",
       "         3.2293e-03, 2.1529e-03, 2.5834e-02, 1.6039e-01, 1.0764e-03, 7.5350e-03,\n",
       "         1.5070e-02, 3.2293e-03, 6.3509e-02, 3.9828e-02, 1.0764e-03, 1.0764e-03,\n",
       "         2.4758e-02, 2.2605e-02, 9.6878e-03, 2.7987e-02, 1.0764e-03, 3.2293e-03,\n",
       "         1.0764e-03, 7.9656e-02, 2.1529e-03],\n",
       "        [2.3673e-01, 1.4921e-01, 2.8694e-03, 7.1736e-03, 8.6083e-03, 5.3085e-02,\n",
       "         5.7389e-03, 1.4347e-03, 2.8694e-03, 1.4778e-01, 1.4347e-03, 1.4347e-03,\n",
       "         5.7389e-02, 2.8694e-03, 2.8694e-03, 6.0258e-02, 1.4347e-03, 1.4347e-03,\n",
       "         1.4347e-03, 4.5911e-02, 1.0187e-01, 8.6083e-03, 1.4347e-03, 5.7389e-03,\n",
       "         5.5954e-02, 4.4476e-02, 2.8694e-02],\n",
       "        [2.0540e-01, 2.1931e-01, 2.8642e-03, 1.1866e-02, 2.7926e-02, 3.0892e-02,\n",
       "         1.3298e-03, 3.1710e-03, 2.3527e-03, 1.9742e-02, 2.4550e-03, 8.8993e-03,\n",
       "         1.1303e-01, 1.5241e-02, 1.8689e-01, 2.7823e-02, 1.6367e-03, 7.1604e-04,\n",
       "         2.9869e-02, 4.1121e-02, 1.0741e-02, 1.4525e-02, 1.0945e-02, 5.1146e-04,\n",
       "         2.9664e-03, 2.4550e-03, 8.0810e-03],\n",
       "        [6.7139e-02, 3.5905e-01, 2.0851e-03, 1.2510e-03, 1.2510e-03, 1.5596e-01,\n",
       "         4.1701e-04, 8.3403e-04, 1.8349e-02, 1.5221e-01, 1.2510e-03, 1.2510e-03,\n",
       "         5.1710e-02, 1.5013e-02, 2.0851e-03, 4.6289e-02, 1.2510e-03, 4.1701e-04,\n",
       "         1.3761e-02, 2.0851e-03, 2.0851e-03, 3.0859e-02, 1.2510e-03, 1.6681e-03,\n",
       "         8.3403e-04, 6.1718e-02, 1.9183e-02]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe24b2a7-1f95-4441-8e1e-594a3e4ab6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood=tensor(-559322.6875)\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the likelihood of the names we observed given the parameter we extracted from that same dataset under the\n",
    "# assumption that the probability distribution of a given character given another character follows a multinomial distribution of parameter vector estimated\n",
    "# from the data.\n",
    "loglikelihood = 0\n",
    "for char in names:\n",
    "    for i, j in zip(\".\" + char, char + \".\" ):  # $ is used to express start character or end character\n",
    "        i1 = stoi[i]\n",
    "        i2 = stoi[j]\n",
    "        loglikelihood += torch.log(P[i1, i2])\n",
    "        \n",
    "print(f'{loglikelihood=}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "406efae9-d133-46cb-9c72-0bc594fa4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a neural network\n",
    "# First get the inputs (xs) and the labels (ys) from our data\n",
    "xs = []\n",
    "ys = []\n",
    "for char in names:\n",
    "    for i, j in zip(\".\" + char, char + \".\" ):  # $ is used to express start character or end character\n",
    "        i1 = stoi[i]\n",
    "        i2 = stoi[j]\n",
    "        xs.append(i1)\n",
    "        ys.append(i2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f1ad3ee-df48-4ef8-b559-084ffc3fd5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d93f40ea-8f53-4e6e-bb96-c333c1023cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the values in xs and ys are simply indexes of letters, they are nominal. That means that the number doesn't mean anything on\n",
    "# its own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f6871bb-f901-4ebb-ab3b-041e89e729b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "yenc = F.one_hot(ys, num_classes = 27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0726fbe5-e769-4b32-9064-09b2a6b2704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a the weights in the neural network\n",
    "g = g = torch.Generator().manual_seed(21483645)\n",
    "\n",
    "W = torch.randn((27,27), generator = g, requires_grad = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce8922a6-17a2-4694-a63f-aaff3a6218a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.item()=3.7502005100250244\n",
      "loss.item()=3.3693087100982666\n",
      "loss.item()=3.1381993293762207\n",
      "loss.item()=2.985227346420288\n",
      "loss.item()=2.8890380859375\n",
      "loss.item()=2.8225796222686768\n",
      "loss.item()=2.7731411457061768\n",
      "loss.item()=2.7355403900146484\n",
      "loss.item()=2.706230640411377\n",
      "loss.item()=2.6827292442321777\n",
      "loss.item()=2.6633713245391846\n",
      "loss.item()=2.647071599960327\n",
      "loss.item()=2.633114814758301\n",
      "loss.item()=2.621004819869995\n",
      "loss.item()=2.6103827953338623\n",
      "loss.item()=2.600978136062622\n",
      "loss.item()=2.5925815105438232\n",
      "loss.item()=2.5850305557250977\n",
      "loss.item()=2.5781960487365723\n",
      "loss.item()=2.571977376937866\n",
      "loss.item()=2.5662930011749268\n",
      "loss.item()=2.56107759475708\n",
      "loss.item()=2.556277275085449\n",
      "loss.item()=2.5518462657928467\n",
      "loss.item()=2.547745943069458\n",
      "loss.item()=2.54394268989563\n",
      "loss.item()=2.5404067039489746\n",
      "loss.item()=2.5371124744415283\n",
      "loss.item()=2.5340373516082764\n",
      "loss.item()=2.531160354614258\n",
      "loss.item()=2.5284647941589355\n",
      "loss.item()=2.5259335041046143\n",
      "loss.item()=2.523552894592285\n",
      "loss.item()=2.521310329437256\n",
      "loss.item()=2.5191943645477295\n",
      "loss.item()=2.517195463180542\n",
      "loss.item()=2.515303611755371\n",
      "loss.item()=2.5135116577148438\n",
      "loss.item()=2.5118112564086914\n",
      "loss.item()=2.5101969242095947\n",
      "loss.item()=2.5086617469787598\n",
      "loss.item()=2.5072007179260254\n",
      "loss.item()=2.505808115005493\n",
      "loss.item()=2.5044803619384766\n",
      "loss.item()=2.5032122135162354\n",
      "loss.item()=2.502000570297241\n",
      "loss.item()=2.5008418560028076\n",
      "loss.item()=2.499732732772827\n",
      "loss.item()=2.498669385910034\n",
      "loss.item()=2.497650146484375\n",
      "loss.item()=2.4966723918914795\n",
      "loss.item()=2.4957327842712402\n",
      "loss.item()=2.4948301315307617\n",
      "loss.item()=2.493961811065674\n",
      "loss.item()=2.493126153945923\n",
      "loss.item()=2.492321491241455\n",
      "loss.item()=2.4915459156036377\n",
      "loss.item()=2.490797996520996\n",
      "loss.item()=2.4900765419006348\n",
      "loss.item()=2.489379644393921\n",
      "loss.item()=2.4887068271636963\n",
      "loss.item()=2.488055944442749\n",
      "loss.item()=2.487426519393921\n",
      "loss.item()=2.4868173599243164\n",
      "loss.item()=2.486227512359619\n",
      "loss.item()=2.48565673828125\n",
      "loss.item()=2.485102653503418\n",
      "loss.item()=2.484565496444702\n",
      "loss.item()=2.4840445518493652\n",
      "loss.item()=2.4835383892059326\n",
      "loss.item()=2.4830472469329834\n",
      "loss.item()=2.482570171356201\n",
      "loss.item()=2.4821057319641113\n",
      "loss.item()=2.4816548824310303\n",
      "loss.item()=2.481215476989746\n",
      "loss.item()=2.4807887077331543\n",
      "loss.item()=2.480372428894043\n",
      "loss.item()=2.4799675941467285\n",
      "loss.item()=2.4795727729797363\n",
      "loss.item()=2.4791882038116455\n",
      "loss.item()=2.478813409805298\n",
      "loss.item()=2.478447675704956\n",
      "loss.item()=2.478090763092041\n",
      "loss.item()=2.4777426719665527\n",
      "loss.item()=2.477403163909912\n",
      "loss.item()=2.477071762084961\n",
      "loss.item()=2.476747989654541\n",
      "loss.item()=2.476431131362915\n",
      "loss.item()=2.4761221408843994\n",
      "loss.item()=2.475820541381836\n",
      "loss.item()=2.475525379180908\n",
      "loss.item()=2.4752368927001953\n",
      "loss.item()=2.474954605102539\n",
      "loss.item()=2.4746789932250977\n",
      "loss.item()=2.4744088649749756\n",
      "loss.item()=2.4741451740264893\n",
      "loss.item()=2.4738869667053223\n",
      "loss.item()=2.4736342430114746\n",
      "loss.item()=2.473386764526367\n",
      "loss.item()=2.473144769668579\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "for i in range(100):\n",
    "    # Forward pass\n",
    "    logits = xenc @ W  # We assume that the dot product will give log odds / log counts\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims = True)  # This is called a softmax function activation\n",
    "    loss = -probs[torch.arange(len(ys)), ys].log().mean()  \n",
    "    print(f'{loss.item()=}')\n",
    "    \n",
    "    # Backward pass\n",
    "    W.grad = None # set the gradient to Zero\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weigths with the weights\n",
    "    W.data +=  - 50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fc502e4-86d2-4ead-9256-ff3a7cfa3560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4731, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a93adb21-8ab2-4f8b-a994-4c664a2b92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chilemaniehen.\n",
      "jnselyatt.\n",
      "abremin.\n",
      "monawarobeslyourina.\n",
      "gus.\n",
      "zusienamwitonisaneril.\n",
      "kren.\n",
      "ahaeiblienin.\n",
      "arolanzyiani.\n",
      "cetonacrenah.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(21483645)\n",
    "for j in range(10):\n",
    "    output  = []\n",
    "    ch_i = 0 # character under its number form\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ch_i]), num_classes = 27).float()\n",
    "        logits = xenc @ W  # We assume that the dot product will give log odds / log counts\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdims = True) \n",
    "        ch_i = torch.multinomial(probs, num_samples = 1, replacement =True, generator = g).item()\n",
    "        output.append(itox[ch_i])\n",
    "        if ch_i == 0 :\n",
    "            print(\"\".join(output))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1c22b-a0c0-4944-a0c1-c08ac8cf15c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
